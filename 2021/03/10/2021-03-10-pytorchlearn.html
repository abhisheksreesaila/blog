<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-03-10-pytorchlearn.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Pytorch">Pytorch<a class="anchor-link" href="#Pytorch"> </a></h1><p><strong>Model Eval</strong></p>
<div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span> <span class="p">:</span>            <span class="c1"># Switch off automatic differentation</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Evaluate models by not considering the batch norm, drop out layers etc.</span>
                                        <span class="c1">##Inference mode</span>
</pre></div>
<p><strong>Detach</strong></p>
<div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>   <span class="c1">#remove a tensor (here &quot;x&quot;) from the computational graph, which reduces memory foot print</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="c1">#detaches and clones a tensor</span>
</pre></div>
<p><strong>Model</strong></p>
<div class="highlight"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    <span class="c1">#model is made up of &quot;sequential&quot; function contaniner.</span>

                     <span class="c1"># sequential(sequential()) # neural networks stacked on top of each other</span>
</pre></div>
<p><strong>Class Activation Map</strong></p>
<ul>
<li>Last layer of activation (before the fully connected layer) shows where the model is focusing.  </li>
<li>Needs a global average pooling layer in the network (such as RESNET)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
</div>

