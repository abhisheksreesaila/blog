{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"rand machine topics\"\n",
    "\n",
    "> \"Everyday Learnings about ML. Random topics\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [machine learning, pytorch]\n",
    "- hide: false\n",
    "- search_exclude: false\n",
    "- image: images/post-thumbnails/pytorch.png\n",
    "- metadata_key1: machine learning\n",
    "- metadata_key2: pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "**Model Eval**\n",
    "\n",
    "```python\n",
    "\n",
    "    with torch.no_grad() :            # Switch off automatic differentation\n",
    "    output = learn.model.eval()(x)  # Evaluate models by not considering the batch norm, drop out layers etc.\n",
    "                                        ##Inference mode\n",
    "```\n",
    "\n",
    "**Detach**\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "    x.detach()   #remove a tensor (here \"x\") from the computational graph, which reduces memory foot print\n",
    "    \n",
    "    y = x.detach().clone() #detaches and clones a tensor\n",
    "\n",
    "```\n",
    "\n",
    "**Model**\n",
    "\n",
    "```python\n",
    "\n",
    "   learn.model[0]    #model is made up of \"sequential\" function contaniner.\n",
    "    \n",
    "                     # sequential(sequential()) # neural networks stacked on top of each other\n",
    "    \n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "**einsum**\n",
    "\n",
    "einsum or Enstein summation is basically short end notation to express actions on tensors (or typically matrices) like transpose, multiplication, sum, dot product etc. \n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "torch.einsum ('ab,bc -> ac', A, B)\n",
    "\n",
    "'ab,bc -> ac'  ==> notation.  a,b,c,d are dimensions. \",\" means multiply \n",
    "\n",
    "You are telling that take 2 inputs of dimensions ab and bc and generate an output that gives ac. \n",
    "\n",
    "A,B ==> matrices\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**Class Activation Map**\n",
    "\n",
    "**Areas used to determine class = activations of the last layer of conv * weights of the fully connected layer**\n",
    "\n",
    "\n",
    "- Last layer of activation (before the fully connected layer) shows where the model is focusing.  \n",
    "- Needs a global average pooling layer in the network (such as RESNET)\n",
    "\n",
    "- Why before global max pooling layer? The max pooling layer before the fully connected layer will squash all local activations, normalize them and feed them to FC. Until then you will have localized features that model is looking at. In other words, you will have location of the image where the model is focused on.  \n",
    "\n",
    "Example :   the activation shape is [512, 7, 7]. Think of this as 512 images of 7x7 size\n",
    "\n",
    "\n",
    "- How does dot product help? the weights in the fully connected layer shows the classifer preference. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
