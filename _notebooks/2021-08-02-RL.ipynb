{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Reinforcement Learning\"\n",
    "\n",
    "> \"RL concepts in 1 place\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [Machine Learning]\n",
    "- hide: false\n",
    "- search_exclude: false\n",
    "- image: images/post-thumbnails/rl.png\n",
    "- metadata_key1: notes\n",
    "- metadata_key2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Basics\n",
    "\n",
    "- Unlike the unsuperivsed or supervised learning algorithms, it is used in dynamic env\n",
    "- There are 2 entities involved: \n",
    "  - AGENT : Software involved in getting input and executing actions\n",
    "  - Environment : House that Agent is in\n",
    "\n",
    "-  Input\n",
    "    - Take a set of observations (or states)\n",
    "- Process  (or policy)\n",
    "    - Figures out the right set of actions\n",
    "    - If we used \"deep learning\" for this, then it becomes deep reinforcement learning\n",
    " \n",
    "- Output\n",
    "    - Right set of commands to follow\n",
    "- Feedback\n",
    "    - It the output received positive feedback, great, keep in mind and repeat when possible\n",
    "    - If not, change\n",
    "\n",
    "## Things to keep in mind in RL\n",
    "\n",
    "### Value vs Reward\n",
    " \n",
    " - Value = long term benefits\n",
    " - Reward = Immediate feedback\n",
    " - If its too long term, env has changed, your algorithm or function is obsolete\n",
    " - too short term, its not a visionary and missed crucial opportunities\n",
    "   \n",
    "### Explore vs Exploit\n",
    " \n",
    " - Agent explores new env and learn ==> updates policy\n",
    " - Agent exploits exising env, fine tunes and gets good at it! \n",
    " - Our problem : balance exploit vs explore\n",
    " \n",
    "### Dynamic Programming\n",
    "\n",
    "- Divides a problem into multiple sub problems\n",
    "- Solves the simplest sub problem first and then does this recurisively until all of them are solved\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
