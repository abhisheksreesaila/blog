<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Deep Learning Basics | ABLearn</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Deep Learning Basics" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Everyday Learnings about ML. Random topics" />
<meta property="og:description" content="Everyday Learnings about ML. Random topics" />
<link rel="canonical" href="https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html" />
<meta property="og:url" content="https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html" />
<meta property="og:site_name" content="ABLearn" />
<meta property="og:image" content="https://ablearn.io/images/post-thumbnails/dl.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-08-11T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html"},"image":"https://ablearn.io/images/post-thumbnails/dl.png","description":"Everyday Learnings about ML. Random topics","@type":"BlogPosting","url":"https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html","headline":"Deep Learning Basics","dateModified":"2021-08-11T00:00:00-05:00","datePublished":"2021-08-11T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ablearn.io/feed.xml" title="ABLearn" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Deep Learning Basics | ABLearn</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Deep Learning Basics" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Everyday Learnings about ML. Random topics" />
<meta property="og:description" content="Everyday Learnings about ML. Random topics" />
<link rel="canonical" href="https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html" />
<meta property="og:url" content="https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html" />
<meta property="og:site_name" content="ABLearn" />
<meta property="og:image" content="https://ablearn.io/images/post-thumbnails/dl.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-08-11T00:00:00-05:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html"},"image":"https://ablearn.io/images/post-thumbnails/dl.png","description":"Everyday Learnings about ML. Random topics","@type":"BlogPosting","url":"https://ablearn.io/deep%20learning/2021/08/11/deep-learning.html","headline":"Deep Learning Basics","dateModified":"2021-08-11T00:00:00-05:00","datePublished":"2021-08-11T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://ablearn.io/feed.xml" title="ABLearn" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">ABLearn</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Categories</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Deep Learning Basics</h1><p class="page-description">Everyday Learnings about ML. Random topics</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-08-11T00:00:00-05:00" itemprop="datePublished">
        Aug 11, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Deep Learning">Deep Learning</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Pytorch">Pytorch </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Drawbacks">Drawbacks </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Pros">Pros </a></li>
<li class="toc-entry toc-h3"><a href="#Cons">Cons </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#References">References </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Matplot-Lib-Basics">Matplot Lib Basics </a></li>
<li class="toc-entry toc-h2"><a href="#Python-Decode-Function">Python Decode Function </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-08-11-deep learning.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Pytorch">
<a class="anchor" href="#Pytorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pytorch<a class="anchor-link" href="#Pytorch"> </a>
</h1>
<p><strong>Model Eval</strong></p>
<div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span> <span class="p">:</span>            <span class="c1"># Switch off automatic differentation</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># Evaluate models by not considering the batch norm, drop out layers etc.</span>
                                        <span class="c1">##Inference mode</span>
</pre></div>
<p><strong>Detach</strong></p>
<p>Remove a tensor (here "x") from the computational graph, which reduces memory foot print.</p>
<p>Detaches and clones a tensor</p>
<div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>   

    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</pre></div>
<p><strong>Model</strong></p>
<div class="highlight"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    <span class="c1">#model is made up of "sequential" function contaniner.</span>

                     <span class="c1"># sequential(sequential()) # neural networks stacked on top of each other</span>
</pre></div>
<p><strong>einsum</strong></p>
<p>einsum or Enstein summation is basically short end notation to express actions on tensors (or typically matrices) like transpose, multiplication, sum, dot product etc.</p>
<div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">einsum</span> <span class="p">(</span><span class="s1">'ab,bc -&gt; ac'</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>

<span class="s1">'ab,bc -&gt; ac'</span>  <span class="o">==&gt;</span> <span class="n">notation</span><span class="o">.</span>  <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">d</span> <span class="n">are</span> <span class="n">dimensions</span><span class="o">.</span> <span class="s2">","</span> <span class="n">means</span> <span class="n">multiply</span> 

<span class="n">You</span> <span class="n">are</span> <span class="n">telling</span> <span class="n">that</span> <span class="n">take</span> <span class="mi">2</span> <span class="n">inputs</span> <span class="n">of</span> <span class="n">dimensions</span> <span class="n">ab</span> <span class="ow">and</span> <span class="n">bc</span> <span class="ow">and</span> <span class="n">generate</span> <span class="n">an</span> <span class="n">output</span> <span class="n">that</span> <span class="n">gives</span> <span class="n">ac</span><span class="o">.</span> 

<span class="n">A</span><span class="p">,</span><span class="n">B</span> <span class="o">==&gt;</span> <span class="n">matrices</span>
</pre></div>
<p><strong>Class Activation Map</strong></p>
<p><strong>Areas used to determine class = activations of the last layer of conv * weights of the fully connected layer</strong></p>
<ul>
<li>Last layer of activation (before the fully connected layer) shows where the model is focusing.  </li>
<li>
<p>Needs a global average pooling layer in the network (such as RESNET)</p>
</li>
<li>
<p>Why before global max pooling layer? 
The global max poolng layer unlike the other maxpool layers will squash all features into 1 linear vector. 
The max pooling layer before the fully connected layer will squash all local activations, normalize them and feed them to FC. Until then you will have localized features that model is looking at. In other words, you will have location of the image where the model is focused on.</p>
</li>
<li>
<p>How does dot product help?</p>
</li>
</ul>
<p><img src="https://abhisheksreesaila.github.io/blog/images/general/cnn1.png" alt="" title="CNN - Training Phase"></p>
<p>Learns Features. Stores Weights</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/general/cnn2.png" alt="" title="CNN - Inference Phase"></p>
<p>Use those weights with the activations and figure which one to focus on, which one to omit.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Drawbacks">
<a class="anchor" href="#Drawbacks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Drawbacks<a class="anchor-link" href="#Drawbacks"> </a>
</h2>
<ul>
<li>The architecture needs to have global max pooling layer. Only then can we take the layer before that.</li>
<li>The method can only look at the final layer of the CNN and show why the model predicted what it did.  It cannot show any later prior.</li>
<li>These drawbacks are addressed by the GRAD GAM described below</li>
</ul>
<ul>
<li>Calculate the gradients by running .backward() function. (Pytorch does not store them, hence need to calc again during inference)</li>
<li>Average the GRADIENTS of the feature maps of the last conv layer (= weights)</li>
<li>Multiply WEIGHTS vs ACTICATIONS (as in CAM) to get the CAM Map to display.</li>
</ul>
<h3 id="Pros">
<a class="anchor" href="#Pros" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pros<a class="anchor-link" href="#Pros"> </a>
</h3>
<ul>
<li>over comes all the issues of vanilla CAM</li>
<li>works for any images tasks (classification, segmentation, vQA)</li>
</ul>
<h3 id="Cons">
<a class="anchor" href="#Cons" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cons<a class="anchor-link" href="#Cons"> </a>
</h3>
<ul>
<li>cannot locate mulitple objects within the images.</li>
</ul>
<p><img src="https://abhisheksreesaila.github.io/blog/images/general/cnn3.png" alt="" title="CNN - GRAD CAM"></p>
<ul>
<li>Why gradients equal same size as activation maps? </li>
</ul>
<p>The gradient is calculated for each pixel in the feature map. For example, if the activation map is 512 x 7 x 7, then then the number of graidents are also 512 x 7 x 7</p>
<ul>
<li>Why averaging gradients yields weights?</li>
</ul>
<p>CAM uses WEIGHTS at the Fully Connected layer to choose the "feature maps" that is more relevant and squash the ones which are not.  So it is highly dependent of (CONV Layer =&gt; Global Average Pooling Layer ==&gt; FC Layer) network.  GRAD-CAM uses this concept by make its more general.
  It uses GRADIENTS to provide the weights. We use the GRADIENTS in the last conv layer, do the global average pooling   ourselves, and now we have our weights!  we dont have to depend on specific GAP layer nor the weights of the fully connected layer. GRADIENTS provide a good enough "weighting mechanism" to pick the feature map that is relevant and squash the one which we dont.
<font size="3">  
**Deep neural networks as well act as information distillation pipeline where the input image is being converted to a domain which is visually less interpretable (by removing irrelevant information) but mathematically useful for convnet to make a choice from the output classes in its last layer**
</font></p>
<h1 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References<a class="anchor-link" href="#References"> </a>
</h1>
<p><a href="https://glassboxmedicine.com/2020/05/29/grad-cam-visual-explanations-from-deep-networks/">https://glassboxmedicine.com/2020/05/29/grad-cam-visual-explanations-from-deep-networks/</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Matplot-Lib-Basics">
<a class="anchor" href="#Matplot-Lib-Basics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Matplot Lib Basics<a class="anchor-link" href="#Matplot-Lib-Basics"> </a>
</h2>
<div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> 

<span class="c1"># Rows = 3; Columns=2; Total = 5 plots === Set the figure size to 5 inches to 5 inches</span>
<span class="c1"># Note that the size is defined in inches, not pixels</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>   <span class="c1">#1st axis</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1">#2nd axis</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1">#3rd axis</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist2d</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1">#4th axis</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  <span class="c1"># show the plot</span>

<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">()</span> <span class="c1"># show the image</span>

<span class="c1">#interpolation = use known data at unknown places (like extrapolate, interpolate)</span>
</pre></div>
<p><a href="https://matplotlib.org/stable/gallery/images_contours_and_fields/interpolation_methods.html">Check out various types here of interpolation here</a></p>
<h2 id="Python-Decode-Function">
<a class="anchor" href="#Python-Decode-Function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Python Decode Function<a class="anchor-link" href="#Python-Decode-Function"> </a>
</h2>
<p>When you encode using a class (string class, data loader class etc.). you can use decode to undo it. Useful in bring back the image to its original form to display while "intrepreting" the test results.</p>
<ul>
<li>
<p>IMAGE ==&gt; RESIZE ==&gt; ENCODE (normalize to image net stats or something similar) ==&gt; Output</p>
</li>
<li>
<p>Output ===&gt; DECODE ==&gt; Original image (but still includes the resize)  ==&gt; Display (-able)</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="abhisheksreesaila/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/deep%20learning/2021/08/11/deep-learning.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Always Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/abhisheksreesaila" target="_blank" title="abhisheksreesaila"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/asreesaila" target="_blank" title="asreesaila"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
