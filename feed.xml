<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://abhisheksreesaila.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://abhisheksreesaila.github.io/blog/" rel="alternate" type="text/html" /><updated>2021-05-09T16:42:16-05:00</updated><id>https://abhisheksreesaila.github.io/blog/feed.xml</id><title type="html">ABLearn</title><subtitle>Casual Programmer</subtitle><entry><title type="html">Apache Spark Notes</title><link href="https://abhisheksreesaila.github.io/blog/big%20data/2021/05/02/Spark.html" rel="alternate" type="text/html" title="Apache Spark Notes" /><published>2021-05-02T00:00:00-05:00</published><updated>2021-05-02T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/big%20data/2021/05/02/Spark</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/big%20data/2021/05/02/Spark.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-05-02-Spark.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/abhisheksreesaila/blog/blob/master/assets/PDFs/Spark_Internals.pdf&quot;&gt;PDF Link&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/Spark_Internals.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Language-:-SCALA&quot;&gt;Language : SCALA&lt;a class=&quot;anchor-link&quot; href=&quot;#Language-:-SCALA&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h2 id=&quot;Common-terms&quot;&gt;Common terms&lt;a class=&quot;anchor-link&quot; href=&quot;#Common-terms&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Unit&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In Scala, the Unit keyword is used to define a function which does not return &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Object&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A singleton is a class that can have only one instance, i.e., Object. You create singleton using the keyword object instead of class keyword.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Trait&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Interface (if you extend it). You can use only 1 extend&lt;/li&gt;
&lt;li&gt;Abstract class if you use WITH keyword. You can use multiple WITH's&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A JAR (Java ARchive) is a package file format typically used to aggregate many Java class files and associated metadata and resources (text, images, etc.) into one file for distribution. -&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;You can build a &quot;thin&quot; JAR file with the sbt package command. Thin JAR files only include the project's classes / objects / traits and don't include any of the project dependencies&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;MAVEN&quot;&gt;MAVEN&lt;a class=&quot;anchor-link&quot; href=&quot;#MAVEN&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Download &lt;a href=&quot;https://www.jetbrains.com/idea/&quot;&gt;https://www.jetbrains.com/idea/&lt;/a&gt;  (community edition)&lt;/li&gt;
&lt;li&gt;Import MAVEN project&lt;/li&gt;
&lt;li&gt;POM.XML   (similar to package.xml) &lt;ul&gt;
&lt;li&gt;Shows all packages required for maven projects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Command within JetBrains&lt;ul&gt;
&lt;li&gt;clean – the project is clean of all artifacts that came from previous compilations &lt;/li&gt;
&lt;li&gt;compile – the project is compiled into /target directory of project root &lt;/li&gt;
&lt;li&gt;install – packaged archive is copied into local maven repository (could in your user's home directory under /.m2) &lt;/li&gt;
&lt;li&gt;test – unit tests are run package – compiled sources are packaged into archive (JAR by default)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Naming-Conventions-in-the-JAVA-world&quot;&gt;Naming Conventions in the JAVA world&lt;a class=&quot;anchor-link&quot; href=&quot;#Naming-Conventions-in-the-JAVA-world&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;groupId&lt;/strong&gt; This element indicates the unique identifier of the organization or group that created the project. The groupId is one of the key identifiers of a project and is typically based on the fully qualified domain name of your organization. For example org.apache.maven.plugins is the designated groupId for all Maven plugins.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;artifactId&lt;/strong&gt; This element indicates the unique base name of the primary artifact being generated by this project. The primary artifact for a project is typically a JAR file. Secondary artifacts like source bundles also use the artifactId as part of their final name. A typical artifact produced by Maven would have the form 
&lt;artifactId&gt;-&lt;version&gt;.&lt;extension&gt; (for example, myapp-1.0.jar).&amp;lt;/p&amp;gt;
&amp;lt;/li&amp;gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;packaging&lt;/strong&gt; This element indicates the package type to be used by this artifact (e.g. JAR, WAR, EAR, etc.). This not only means if the artifact produced is JAR, WAR, or EAR but can also indicate a specific lifecycle to use as part of the build process. (The lifecycle is a topic we will deal with further on in the guide. For now, just keep in mind that the indicated packaging of a project can play a part in customizing the build lifecycle.) The default value for the packaging element is JAR so you do not have to specify this for most projects.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;version&lt;/strong&gt; This element indicates the version of the artifact generated by the project. Maven goes a long way to help you with version management and you will often see the SNAPSHOT designator in a version, which indicates that a project is in a state of development. We will discuss the use of snapshots and how they work further on in this guide.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;name&lt;/strong&gt; This element indicates the display name used for the project. This is often used in Maven's generated documentation.&lt;/p&gt;
&lt;/li&gt;
&amp;lt;/ol&amp;gt;

&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&amp;lt;/div&amp;gt;
 

&lt;/extension&gt;&lt;/version&gt;&lt;/artifactId&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/Apache_Spark_logo.png" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/Apache_Spark_logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Clean Code By Robert C Martin Notes</title><link href="https://abhisheksreesaila.github.io/blog/others/2021/05/01/CleanCode.html" rel="alternate" type="text/html" title="Clean Code By Robert C Martin Notes" /><published>2021-05-01T00:00:00-05:00</published><updated>2021-05-01T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/others/2021/05/01/CleanCode</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/others/2021/05/01/CleanCode.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-05-01-CleanCode.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;WIP&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Classes&quot;&gt;Classes&lt;a class=&quot;anchor-link&quot; href=&quot;#Classes&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Single responsibility&lt;/li&gt;
&lt;li&gt;Break it&lt;/li&gt;
&lt;li&gt;Domain Driven&lt;/li&gt;
&lt;li&gt;Inject Object &amp;amp; code Interfaces&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Comments&quot;&gt;Comments&lt;a class=&quot;anchor-link&quot; href=&quot;#Comments&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;To Amplify&lt;/li&gt;
&lt;li&gt;TODOS&lt;/li&gt;
&lt;li&gt;Remove Unnecessary&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Functions&quot;&gt;Functions&lt;a class=&quot;anchor-link&quot; href=&quot;#Functions&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;1 thing to do&lt;/li&gt;
&lt;li&gt;no args (preferred)&lt;/li&gt;
&lt;li&gt;1/2 OK&lt;/li&gt;
&lt;li&gt;3 or more = bad&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/code.png" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/code.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Basic ML Topics</title><link href="https://abhisheksreesaila.github.io/blog/machine%20learning/2021/04/29/ML.html" rel="alternate" type="text/html" title="Basic ML Topics" /><published>2021-04-29T00:00:00-05:00</published><updated>2021-04-29T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/machine%20learning/2021/04/29/ML</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/machine%20learning/2021/04/29/ML.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-04-29-ML.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Padding-in-CNNs&quot;&gt;Padding in CNNs&lt;a class=&quot;anchor-link&quot; href=&quot;#Padding-in-CNNs&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Why use padding? In addition to the aforementioned benefit of keeping the spatial sizes constant after CONV, doing &lt;strong&gt;this actually improves performance&lt;/strong&gt;. If the CONV layers were to not zero-pad the inputs and only perform valid convolutions, then the size of the volumes would reduce by a small amount after each CONV, &lt;strong&gt;and the information at the borders would be “washed away” too quickly&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.kaggle.com/c/data-science-bowl-2018/discussion/54426&quot;&gt;Reference&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Linear-vs-Logistic-Regression&quot;&gt;Linear vs Logistic Regression&lt;a class=&quot;anchor-link&quot; href=&quot;#Linear-vs-Logistic-Regression&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;In linear regression, &lt;strong&gt;the outcome (dependent variable) is continuous&lt;/strong&gt;. It can have any one of an infinite number of possible values.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;If X contains the area in square feet of houses,  (200, 300, 3000) Y contains the corresponding sale price of those houses, ($1000, $2000, $200,000)linear regression to predict selling price as a function of house size Y = f(x)&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In logistic regression, the outcome (dependent variable) has only a &lt;strong&gt;limited number of possible values&lt;/strong&gt;. Logistic Regression is used when response variable is &lt;em&gt;categorical&lt;/em&gt; in nature&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;If, instead, you wanted to predict, based on size, whether a house would sell for more than 200K, you would use logistic regression. The possible outputs are either Yes, the house will sell for more than 200K, or No, the house will not&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;What-is-data-augmentation?&quot;&gt;What is data augmentation?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-is-data-augmentation?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Overfitting is caused by having too few samples to learn from, rendering us unable to train a model able to generalize to new data. Given infinite data, our model would be exposed to every possible aspect of the data distribution at hand: we would never overfit. Data augmentation takes the approach of generating more training data from existing training samples, by &quot;augmenting&quot; the samples via a number of random transformations that yield believable-looking images. &lt;strong&gt;The goal is that at training time, our model would never see the exact same picture twice&lt;/strong&gt;. This helps the model get exposed to more aspects of the data and generalize better.&lt;/p&gt;
&lt;h2 id=&quot;What-is-Momentum?&quot;&gt;What is Momentum?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-is-Momentum?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Momentum helps to speed the optimization process toward the minimum of the loss and get out of saddle points by adding a running average of previous gradients and use that average instead of the current batch of data. It forces the gradient descent toward the correct direction to the loss by making the convergence faster and by reducing oscillations&lt;/p&gt;
&lt;h2 id=&quot;What-is-learning-rate?&quot;&gt;What is learning rate?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-is-learning-rate?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The learning rate is how quickly or how slowly a network updates old parameters for new ones. By default, the learning rate is held constant, however, this way may cause some issues such as:
    • If the learning rate is too small, it will take a long time to reach the optimum, or maybe never reach it.
    • If the learning rate is too big, it will keep bouncing around the optimum.
The optimization method may get stuck in shallow valleys!&lt;/p&gt;
&lt;h2 id=&quot;What-are-auto-encoders?&quot;&gt;What are auto-encoders?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-are-auto-encoders?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Autoencoders are a specific type of feedforward neural networks where the input is the same as the output. They compress the input into a lower-dimensional code and then reconstruct the output from this representation. The code is a compact “summary” or “compression” of the input, also called the latent-space representation.
An autoencoder consists of 3 components: encoder, code and decoder. The encoder compresses the input and produces the code, the decoder then reconstructs the input only using this code.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/autoencoder.png&quot; alt=&quot;&quot; title=&quot;Auto Encoder&quot; /&gt;&lt;/p&gt;
&lt;p&gt;To build an autoencoder we need 3 things: an encoding method, decoding method, and a loss function to compare the output with the target. Autoencoders are mainly a dimensionality reduction (or compression) algorithm with a couple of important properties&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data specific&lt;/li&gt;
&lt;li&gt;Lossy&lt;/li&gt;
&lt;li&gt;Unsupervised&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Why-batches-in-training-ml-model?&quot;&gt;Why batches in training ml model?&lt;a class=&quot;anchor-link&quot; href=&quot;#Why-batches-in-training-ml-model?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Ideally, we'd like to use all our data for every step of training because that would give us a better sense of what we should be doing, but that's expensive. So, instead, we use a &lt;strong&gt;different subset every time&lt;/strong&gt;. Doing this is cheap and has much of the same benefit&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/ml.png" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/ml.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">NVIDA GTC 2021 Summary</title><link href="https://abhisheksreesaila.github.io/blog/others/2021/04/18/NVIDA-GTC-2021-Summary.html" rel="alternate" type="text/html" title="NVIDA GTC 2021 Summary" /><published>2021-04-18T00:00:00-05:00</published><updated>2021-04-18T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/others/2021/04/18/NVIDA-GTC-2021-Summary</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/others/2021/04/18/NVIDA-GTC-2021-Summary.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-04-18-NVIDA GTC 2021 Summary.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Overall&quot;&gt;Overall&lt;a class=&quot;anchor-link&quot; href=&quot;#Overall&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Most of the current self driving problems seems to have been related to simulation-to-real deployment. Simulations have to get better, time for creating such scenarios have to be very small to be productive.&lt;/p&gt;
&lt;h1 id=&quot;Future-of-Self-Driving&quot;&gt;Future of Self Driving&lt;a class=&quot;anchor-link&quot; href=&quot;#Future-of-Self-Driving&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;4 issues currently.&lt;/p&gt;
&lt;p&gt;virtual scenarios
virtual worlds
Virtual behaviors&lt;/p&gt;
&lt;h1 id=&quot;Energy-Based-Learning&quot;&gt;Energy Based Learning&lt;a class=&quot;anchor-link&quot; href=&quot;#Energy-Based-Learning&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Based on self supervised learning&lt;/p&gt;
&lt;p&gt;2 types
    limited samples - model derives patterns
    no samples - model derives patterns&lt;/p&gt;
&lt;h1 id=&quot;Zoosk---Car-riding-company&quot;&gt;Zoosk - Car riding company&lt;a class=&quot;anchor-link&quot; href=&quot;#Zoosk---Car-riding-company&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Symmetrical car design&lt;/li&gt;
&lt;li&gt;Facilitates more effective spacing of sensors&lt;/li&gt;
&lt;li&gt;Tested on SF urban roads&lt;/li&gt;
&lt;li&gt;Highlighted that simulations are more effective and hence needs to become even better. &lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Azure-AI-for-Earth-Planetary-Compute&quot;&gt;Azure AI for Earth Planetary Compute&lt;a class=&quot;anchor-link&quot; href=&quot;#Azure-AI-for-Earth-Planetary-Compute&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/gtc2021.jpg" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/gtc2021.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Understand Azure AD and OAuth 2.0</title><link href="https://abhisheksreesaila.github.io/blog/azure/2021/04/14/AzureAD.html" rel="alternate" type="text/html" title="Understand Azure AD and OAuth 2.0" /><published>2021-04-14T00:00:00-05:00</published><updated>2021-04-14T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/azure/2021/04/14/AzureAD</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/azure/2021/04/14/AzureAD.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-04-14-AzureAD.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Purpose&quot;&gt;Purpose&lt;a class=&quot;anchor-link&quot; href=&quot;#Purpose&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Understand Azure AD OAuth 2.0 Token Generation and Validation&lt;/p&gt;
&lt;h1 id=&quot;Terms&quot;&gt;Terms&lt;a class=&quot;anchor-link&quot; href=&quot;#Terms&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Azure AD = Azure Active Directory&lt;/li&gt;
&lt;li&gt;OAuth 2.0 = Protocol&lt;/li&gt;
&lt;li&gt;OpenIDConnect = Library that makes it easy to setup custom OAuth and Setup Azure&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Steps&quot;&gt;Steps&lt;a class=&quot;anchor-link&quot; href=&quot;#Steps&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&quot;Registration&quot;&gt;Registration&lt;a class=&quot;anchor-link&quot; href=&quot;#Registration&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Register your app within AzureAD&lt;ul&gt;
&lt;li&gt;You will get an APP ID and TENANT ID&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Create-a-secret&quot;&gt;Create a secret&lt;a class=&quot;anchor-link&quot; href=&quot;#Create-a-secret&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Create a client secret OR&lt;/li&gt;
&lt;li&gt;Create a certificate in Azure Key Vault &lt;/li&gt;
&lt;li&gt;Upload the .cer&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Get-the-OAuth-JWT-Token&quot;&gt;Get the OAuth JWT Token&lt;a class=&quot;anchor-link&quot; href=&quot;#Get-the-OAuth-JWT-Token&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Azure AD will provide you with endpoints&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Request Template&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provide the APPID and secret&lt;/li&gt;
&lt;li&gt;grant_type = client_credentials&lt;/li&gt;
&lt;li&gt;scope : api://&amp;lt;&lt;appid&gt;&amp;gt;&amp;lt;/li&amp;gt;
&amp;lt;/ul&amp;gt;
&amp;lt;/li&amp;gt;
&lt;li&gt;&lt;p&gt;Response will be JWT token&lt;/p&gt;
&lt;/li&gt;
&amp;lt;/ul&amp;gt;
&lt;h2 id=&quot;Access-Control&quot;&gt;Access Control&lt;a class=&quot;anchor-link&quot; href=&quot;#Access-Control&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;App level permission - set roles&lt;ul&gt;
&lt;li&gt;works with token endpoints&lt;/li&gt;
&lt;li&gt;works at the app level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Delegate permissions - set scopes&lt;ul&gt;
&lt;li&gt;works with authorize endpoints&lt;/li&gt;
&lt;li&gt;works at a more granular level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Add-a-authorized-client-application&quot;&gt;Add a authorized client application&lt;a class=&quot;anchor-link&quot; href=&quot;#Add-a-authorized-client-application&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;for any app withih the same subscription (or another subscription in cases for mulit-tenant apps)&lt;ul&gt;
&lt;li&gt;Go to &quot;expose an API -&amp;gt; add a authorized client application&quot;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;this helps to use the same app registration and its corresponding configuration but all related apps.
&lt;pre&gt;&lt;code&gt; - In other words, 1 app registration can accomodate multiple apps&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;Add-roles-and-permission&quot;&gt;Add roles and permission&lt;a class=&quot;anchor-link&quot; href=&quot;#Add-roles-and-permission&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/div&amp;gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&amp;lt;/div&amp;gt;
 

&lt;/appid&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/Azure-AD-Domain-Services.png" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/Azure-AD-Domain-Services.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">how to take notes?</title><link href="https://abhisheksreesaila.github.io/blog/others/2021/03/30/MindMap.html" rel="alternate" type="text/html" title="how to take notes?" /><published>2021-03-30T00:00:00-05:00</published><updated>2021-03-30T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/others/2021/03/30/MindMap</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/others/2021/03/30/MindMap.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-03-30-MindMap.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Mind-Map.--Why?&quot;&gt;Mind Map.  Why?&lt;a class=&quot;anchor-link&quot; href=&quot;#Mind-Map.--Why?&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;If you take a cross section of the brain, its looks like interconnected wires. If you model your outside world, like the internal, then its &quot;natural&quot; and promotes better creation of new ideas. If your force yourself to be &quot;neat&quot; then there is friction or what is commonly known as the &quot;writers block&quot;.&lt;/p&gt;
&lt;p&gt;While traditional list-based note taking works, mind map takes this to the next level by adding color, images and free flow format that is absent in lists. This has helped me refer the material easily since i can glance all-at-once quickly, or go to a section without hunting and pecking. Colors and images aids recall and presents the materials in a fun and entertaining way and makes the whole note-taking experience &quot;playful&quot; rather than work.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/mindmap_adv.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;Mind-Map.--How?&quot;&gt;Mind Map.  How?&lt;a class=&quot;anchor-link&quot; href=&quot;#Mind-Map.--How?&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&quot;Guidelines&quot;&gt;Guidelines&lt;a class=&quot;anchor-link&quot; href=&quot;#Guidelines&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Start with a central idea&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Radiate outwards&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Big BOLD letter&lt;/strong&gt; in the beginning. (main topics)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;branch to sub-topics&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add &lt;font color=&quot;red&quot;&gt;col&lt;/font&gt;  &lt;font color=&quot;blue&quot;&gt;ors&lt;/font&gt;  to each branch&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add images whereever possible&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All branches have to be curved.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;step-by-step-working&quot;&gt;step by step working&lt;a class=&quot;anchor-link&quot; href=&quot;#step-by-step-working&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Draw a big central topic&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Branch out sub-topics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Color them&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Curve them&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Go to each topic and again branch out.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add doodles and imagess&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You will be uncomfortable at first. since the mind is getting used to it (from lists)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Then you will generate ideas that you thought was impossible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Branches are THICK at the center and thins towards the edges&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See below for visuals&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/mindmap-concepts.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;Mind-Map.--When?&quot;&gt;Mind Map.  When?&lt;a class=&quot;anchor-link&quot; href=&quot;#Mind-Map.--When?&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Note taking&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Brain storming. Infact its a perfect ideation tool as it does not restrict in a specific direction&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Language Learning&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Project Planning (shows all the inter-dependencies between various parties)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TODO LIST&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/notes.jpeg" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/notes.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">rand robotics topics</title><link href="https://abhisheksreesaila.github.io/blog/robotics/2021/03/23/robotics.html" rel="alternate" type="text/html" title="rand robotics topics" /><published>2021-03-23T00:00:00-05:00</published><updated>2021-03-23T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/robotics/2021/03/23/robotics</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/robotics/2021/03/23/robotics.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-03-23-robotics.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Kalman-Filter-Intuition&quot;&gt;Kalman Filter Intuition&lt;a class=&quot;anchor-link&quot; href=&quot;#Kalman-Filter-Intuition&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;PURPOSE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kalman Filter are useful tools to measure something that cannot be measured directly! You gather all the attributes to measure it indirectly. Example : you cannot measure the moving vehicle position w.r.t to its surroundings, so use LIDAR to throw light at them and measure the reflections back to create a map of the objects around it.  Its not going to be perfect, but its a good approx. Another example is SONAR - Measure the speed of sound reflection to measure ocean's depth.&lt;/p&gt;
&lt;p&gt;Kalman filter has the these high level components:-&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PREDICTION&lt;/strong&gt; - Predict the next state of the object. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MEASUREMENT&lt;/strong&gt; - Measure the current state of the object.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CONFIDENCE&lt;/strong&gt; - How good (or bad) the PREDICTED or MEASUREMENT values are&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kalman filter (or variants) have the following intuition.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CURRENT STATE&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Suppose current time is 3:00pm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;PREDICTION over MEASUREMENT&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After few mins, we look at the watch again and we PREDICT its 3:04pm, but its shows 3:55pm!! &lt;/li&gt;
&lt;li&gt;We know the MEASUREMENT is wrong and  have every reason to believe the PREDICTION is more acccurate and set the watch to be 3:04pm. Our CONFIDENCE in the MEASUREMENT is shaken, we believe it is so noisy to show 3:55pm &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;MEASUREMENT over PREDICTION&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the other hand, if the measurement shows 3:05 pm, we have greater confidence that MEASUREMENT is correct, since its more or less in line with our expectations and since its actually measured, thats should be more accurate. Here we trust or more CONFIDENCE in the MEASUREMENT. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Limitations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kalman filters assumes the measurements and noise to have an gaussian distrbution. 
Does not suport multi-modal?&lt;/p&gt;
&lt;h2 id=&quot;Path-Planning&quot;&gt;Path Planning&lt;a class=&quot;anchor-link&quot; href=&quot;#Path-Planning&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Djikistra-algorithm&quot;&gt;Djikistra algorithm&lt;a class=&quot;anchor-link&quot; href=&quot;#Djikistra-algorithm&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We have a map&lt;/li&gt;
&lt;li&gt;We know the starting location and ending location&lt;/li&gt;
&lt;li&gt;We know the cost to reach any node in the map  i.e we have a weighted graph&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start at the source node. We maintain a tracker variable for registering its cost from source.&lt;/li&gt;
&lt;li&gt;Since its origin, it is 0&lt;ul&gt;
&lt;li&gt;Add this to your path list&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Find neighbouring nodes&lt;ul&gt;
&lt;li&gt;Update the tracker variable from &quot;infinity&quot; to the cost from (source -&amp;gt; neighbouring node)&lt;/li&gt;
&lt;li&gt;If the node is already reached, then update the value of tracker only if its lesser than earlier value.&lt;/li&gt;
&lt;li&gt;The &quot;value&quot; calculated from the source node.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stop, when you reach the destination node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It will give the shortest node from any node to all other nodes provided they are reachable from source.&lt;/p&gt;
&lt;p&gt;As always, lets look at it visually!&lt;/p&gt;
&lt;p&gt;Assume the cost between each cell is 1.&lt;/p&gt;
&lt;p&gt;Visit each cell until you reach the TARGET node&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/DJK_Algo.png&quot; alt=&quot;&quot; title=&quot;Dijkstra Algorithm&quot; /&gt;&lt;/p&gt;
&lt;h1 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZmQIkBws4LA&quot;&gt;ConstructSIM&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Reinforcement-Learning-Basics&quot;&gt;Reinforcement Learning Basics&lt;a class=&quot;anchor-link&quot; href=&quot;#Reinforcement-Learning-Basics&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;h1 id=&quot;Working-of-A#-(subset-of-Djikistra)&quot;&gt;Working of A# (subset of Djikistra)&lt;a class=&quot;anchor-link&quot; href=&quot;#Working-of-A#-(subset-of-Djikistra)&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;h1 id=&quot;Working-of-RRT-(Rapid-Exploring-Random-Tree)&quot;&gt;Working of RRT (Rapid Exploring Random Tree)&lt;a class=&quot;anchor-link&quot; href=&quot;#Working-of-RRT-(Rapid-Exploring-Random-Tree)&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/robotics.jpg" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/robotics.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Pytorch Topics</title><link href="https://abhisheksreesaila.github.io/blog/machine%20learning/2021/03/10/Pytorch.html" rel="alternate" type="text/html" title="Pytorch Topics" /><published>2021-03-10T00:00:00-06:00</published><updated>2021-03-10T00:00:00-06:00</updated><id>https://abhisheksreesaila.github.io/blog/machine%20learning/2021/03/10/Pytorch</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/machine%20learning/2021/03/10/Pytorch.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-03-10-Pytorch.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Pytorch&quot;&gt;Pytorch&lt;a class=&quot;anchor-link&quot; href=&quot;#Pytorch&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Model Eval&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Switch off automatic differentation&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Evaluate models by not considering the batch norm, drop out layers etc.&lt;/span&gt;
                                        &lt;span class=&quot;c1&quot;&gt;##Inference mode&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Detach&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Remove a tensor (here &quot;x&quot;) from the computational graph, which reduces memory foot print.&lt;/p&gt;
&lt;p&gt;Detaches and clones a tensor&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;   

    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;#model is made up of &amp;quot;sequential&amp;quot; function contaniner.&lt;/span&gt;

                     &lt;span class=&quot;c1&quot;&gt;# sequential(sequential()) # neural networks stacked on top of each other&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;einsum&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;einsum or Enstein summation is basically short end notation to express actions on tensors (or typically matrices) like transpose, multiplication, sum, dot product etc.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;einsum&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ab,bc -&amp;gt; ac&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;s1&quot;&gt;&amp;#39;ab,bc -&amp;gt; ac&amp;#39;&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;notation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;are&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dimensions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;,&amp;quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;means&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt; 

&lt;span class=&quot;n&quot;&gt;You&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;are&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;telling&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;that&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;take&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dimensions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ab&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bc&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;that&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gives&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ac&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; 

&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrices&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Class Activation Map&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Areas used to determine class = activations of the last layer of conv * weights of the fully connected layer&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Last layer of activation (before the fully connected layer) shows where the model is focusing.  &lt;/li&gt;
&lt;li&gt;&lt;p&gt;Needs a global average pooling layer in the network (such as RESNET)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Why before global max pooling layer? 
The global max poolng layer unlike the other maxpool layers will squash all features into 1 linear vector. 
The max pooling layer before the fully connected layer will squash all local activations, normalize them and feed them to FC. Until then you will have localized features that model is looking at. In other words, you will have location of the image where the model is focused on.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;How does dot product help?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/cnn1.png&quot; alt=&quot;&quot; title=&quot;CNN - Training Phase&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Learns Features. Stores Weights&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/cnn2.png&quot; alt=&quot;&quot; title=&quot;CNN - Inference Phase&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Use those weights with the activations and figure which one to focus on, which one to omit.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Drawbacks&quot;&gt;Drawbacks&lt;a class=&quot;anchor-link&quot; href=&quot;#Drawbacks&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The architecture needs to have global max pooling layer. Only then can we take the layer before that.&lt;/li&gt;
&lt;li&gt;The method can only look at the final layer of the CNN and show why the model predicted what it did.  It cannot show any later prior.&lt;/li&gt;
&lt;li&gt;These drawbacks are addressed by the GRAD GAM described below&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Calculate the gradients by running .backward() function. (Pytorch does not store them, hence need to calc again during inference)&lt;/li&gt;
&lt;li&gt;Average the GRADIENTS of the feature maps of the last conv layer (= weights)&lt;/li&gt;
&lt;li&gt;Multiply WEIGHTS vs ACTICATIONS (as in CAM) to get the CAM Map to display.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Pros&quot;&gt;Pros&lt;a class=&quot;anchor-link&quot; href=&quot;#Pros&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;over comes all the issues of vanilla CAM&lt;/li&gt;
&lt;li&gt;works for any images tasks (classification, segmentation, vQA)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Cons&quot;&gt;Cons&lt;a class=&quot;anchor-link&quot; href=&quot;#Cons&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;cannot locate mulitple objects within the images.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/cnn3.png&quot; alt=&quot;&quot; title=&quot;CNN - GRAD CAM&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why gradients equal same size as activation maps? &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The gradient is calculated for each pixel in the feature map. For example, if the activation map is 512 x 7 x 7, then then the number of graidents are also 512 x 7 x 7&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why averaging gradients yields weights?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CAM uses WEIGHTS at the Fully Connected layer to choose the &quot;feature maps&quot; that is more relevant and squash the ones which are not.  So it is highly dependent of (CONV Layer =&amp;gt; Global Average Pooling Layer ==&amp;gt; FC Layer) network.  GRAD-CAM uses this concept by make its more general.
  It uses GRADIENTS to provide the weights. We use the GRADIENTS in the last conv layer, do the global average pooling   ourselves, and now we have our weights!  we dont have to depend on specific GAP layer nor the weights of the fully connected layer. GRADIENTS provide a good enough &quot;weighting mechanism&quot; to pick the feature map that is relevant and squash the one which we dont.
&lt;font size=&quot;3&quot;&gt;  
Deep neural networks as well act as information distillation pipeline where the input image is being converted to a domain which is visually less interpretable (by removing irrelevant information) but mathematically useful for convnet to make a choice from the output classes in its last layer
&lt;/font&gt;&lt;/p&gt;
&lt;h1 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://glassboxmedicine.com/2020/05/29/grad-cam-visual-explanations-from-deep-networks/&quot;&gt;https://glassboxmedicine.com/2020/05/29/grad-cam-visual-explanations-from-deep-networks/&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Matplot-Lib-Basics&quot;&gt;Matplot Lib Basics&lt;a class=&quot;anchor-link&quot; href=&quot;#Matplot-Lib-Basics&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 

&lt;span class=&quot;c1&quot;&gt;# Rows = 3; Columns=2; Total = 5 plots === Set the figure size to 5 inches to 5 inches&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Note that the size is defined in inches, not pixels&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;#1st axis&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#2nd axis&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#3rd axis&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;axs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#4th axis&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# show the plot&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# show the image&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#interpolation = use known data at unknown places (like extrapolate, interpolate)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://matplotlib.org/stable/gallery/images_contours_and_fields/interpolation_methods.html&quot;&gt;Check out various types here of interpolation here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Python-Decode-Function&quot;&gt;Python Decode Function&lt;a class=&quot;anchor-link&quot; href=&quot;#Python-Decode-Function&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When you encode using a class (string class, data loader class etc.). you can use decode to undo it. Useful in bring back the image to its original form to display while &quot;intrepreting&quot; the test results.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;IMAGE ==&amp;gt; RESIZE ==&amp;gt; ENCODE (normalize to image net stats or something similar) ==&amp;gt; Output&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Output ===&amp;gt; DECODE ==&amp;gt; Original image (but still includes the resize)  ==&amp;gt; Display (-able)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/pytorch.png" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/pytorch.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Atomic Habits - Review</title><link href="https://abhisheksreesaila.github.io/blog/others/2021/03/09/AtomicHabits.html" rel="alternate" type="text/html" title="Atomic Habits - Review" /><published>2021-03-09T00:00:00-06:00</published><updated>2021-03-09T00:00:00-06:00</updated><id>https://abhisheksreesaila.github.io/blog/others/2021/03/09/AtomicHabits</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/others/2021/03/09/AtomicHabits.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-03-09-AtomicHabits.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Purpose&quot;&gt;Purpose&lt;a class=&quot;anchor-link&quot; href=&quot;#Purpose&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Summarize the book &quot;Atomic Habits&quot;&lt;/p&gt;
&lt;h2 id=&quot;Start-Small-(like-really-really-really-small)&quot;&gt;Start Small (like really really really small)&lt;a class=&quot;anchor-link&quot; href=&quot;#Start-Small-(like-really-really-really-small)&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;If you want to develop a habit, start small. But people tend to start big even if they think its small. &lt;/li&gt;
&lt;li&gt;The book talks about how a person wanting to get to GYM, started going to GYM, stay for 5 mins and come back home, for 4 weeks. &lt;/li&gt;
&lt;li&gt;Eventually he developed a habit to go to GYM and become better. The principle is &lt;strong&gt;&quot;Standardize, then optimize&quot;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The book recommends the 2 minute rule :  The first version of the should be so small that it can be started and completed within 2 minutes.  (just like the line i am typing right now**)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;It's-ok-to-miss-a-day.-but-not-2.&quot;&gt;It's ok to miss a day. but not 2.&lt;a class=&quot;anchor-link&quot; href=&quot;#It's-ok-to-miss-a-day.-but-not-2.&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Often we going to strict routine and follow them to the tee, and after a day of disruption, give up telling ourselves that its worthless. &lt;/li&gt;
&lt;li&gt;Missing 1 day is OK, dont miss 2 in a row. &lt;/li&gt;
&lt;li&gt;Getting back in line is still waaaaaay better than giving up all the way.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Connecting-developing-one-to-an-already-developed-habit&quot;&gt;Connecting developing one to an already developed habit&lt;a class=&quot;anchor-link&quot; href=&quot;#Connecting-developing-one-to-an-already-developed-habit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;If you want to floss, keep next to the tooth brush&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Remove-friction-towards-good-ones.&quot;&gt;Remove friction towards good ones.&lt;a class=&quot;anchor-link&quot; href=&quot;#Remove-friction-towards-good-ones.&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;If you are going to GYM, then &lt;strong&gt;think of the smallest of things&lt;/strong&gt; like direction of driving, getting water, clothes in your closet etc. because each one of them are contributing to your resistance. When you remove them or smoothen them out, it will easy not to miss GYM and before you know you are on your way!!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Increase-friction-towards-bad-ones&quot;&gt;Increase friction towards bad ones&lt;a class=&quot;anchor-link&quot; href=&quot;#Increase-friction-towards-bad-ones&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Just place your remote in the other room and you wont watch hours of TV. &lt;/li&gt;
&lt;li&gt;Just remove favorites in your browser and you wont watch youtube&lt;/li&gt;
&lt;li&gt;Just move the junk good to a upper shelf, you will stop eating junk&lt;/li&gt;
&lt;li&gt;Place the phone in the other room, you will stop addicted to your phone&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Avoiding-Procastination&quot;&gt;Avoiding Procastination&lt;a class=&quot;anchor-link&quot; href=&quot;#Avoiding-Procastination&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We always value present than future.  unless the present is rewarding we wont start.  we will look to the dream of achieving instead of hard work. Make the present rewarding, pleasant.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Break the future goal into different steps.&lt;/li&gt;
&lt;li&gt;Ask yourself how you can enjoy the present.  Series of such experiences should be connected to a goal you are seeking.&lt;/li&gt;
&lt;li&gt;GOAL : Getting fit is the goal, but going to GYM is bad
soln 1: Go to Gym and then you can get watch netflix for 30 mins
soln 2 : Better, go to treadmill and watch netflix in the gym&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Develop-an-identity-based-habit&quot;&gt;Develop an identity based habit&lt;a class=&quot;anchor-link&quot; href=&quot;#Develop-an-identity-based-habit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When we develop a habit, the best way to stick to it is cultivate an identity around it. For example, the goal is not be read 100 books, but the goal should be phrased to be say &quot;the goal is to become a READER&quot;. the goal is not to run a marathon, but become a RUNNER&quot;.&lt;/p&gt;
&lt;p&gt;Habit : Daily GITHUB check-ins. lot of work today. so added a 2 min rule (which took 2 mins to complete)&lt;/p&gt;
&lt;h2 id=&quot;Habits-can-get-boring&quot;&gt;Habits can get boring&lt;a class=&quot;anchor-link&quot; href=&quot;#Habits-can-get-boring&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;When we develop a new habit, pretty soon the novelty dies and we can slip into complancency. Most habits we seek and develop require constant improvement. Instead of aiming to drastic improvements and giving up, we should seek organic small improvements. &lt;strong&gt;In others words, aim for constant, small enough to make improvements with little effort and but LARGE enough to feel satisified&lt;/strong&gt;  At first, it can become a trial-and-error but you can reach local optimum pretty quickly and continue the effort OR else you will give up the habits you started with. For eg.  workouts.&lt;/p&gt;
&lt;p&gt;Boredom (not failure) is impediment to success. Professionals stick to schedule while amateurs lets life &quot;get in the way&quot;&lt;/p&gt;
&lt;h3 id=&quot;Importance-of-Genes-in-building-habits&quot;&gt;Importance of Genes in building habits&lt;a class=&quot;anchor-link&quot; href=&quot;#Importance-of-Genes-in-building-habits&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Genes only clarify what we need to choose to work on (not eliminate the need to work on)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://jamesclear.com&quot;&gt;James Clear Website and Book&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/AtomicHabits.png" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/AtomicHabits.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">On your mark…</title><link href="https://abhisheksreesaila.github.io/blog/self%20driving/2020/09/07/FinalSteps.html" rel="alternate" type="text/html" title="On your mark..." /><published>2020-09-07T00:00:00-05:00</published><updated>2020-09-07T00:00:00-05:00</updated><id>https://abhisheksreesaila.github.io/blog/self%20driving/2020/09/07/FinalSteps</id><content type="html" xml:base="https://abhisheksreesaila.github.io/blog/self%20driving/2020/09/07/FinalSteps.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-07-FinalSteps.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Purpose&quot;&gt;Purpose&lt;a class=&quot;anchor-link&quot; href=&quot;#Purpose&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Create a map, configure VISUALIZATION and watch the car self-drive!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/general/rviz_process_flowchart.png&quot; alt=&quot;&quot; title=&quot;Process Flow&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;Visualization&quot;&gt;Visualization&lt;a class=&quot;anchor-link&quot; href=&quot;#Visualization&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;What-is-RVIZ-and-how-do-i-get-it?&quot;&gt;What is RVIZ and how do i get it?&lt;a class=&quot;anchor-link&quot; href=&quot;#What-is-RVIZ-and-how-do-i-get-it?&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;rviz is a 3D visualizer for the Robot Operating System (ROS) framework. Here we need to visualize and track car's movements in your laptop computer. So you have to set the variables correctly so that CAR can send the messages to your computer and vice-versa.&lt;/p&gt;
&lt;h4 id=&quot;FAQs&quot;&gt;FAQs&lt;a class=&quot;anchor-link&quot; href=&quot;#FAQs&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;1. Why can't I open RVIZ directly by SSH-ing to car? In other words, why do i need laptop computer to open up RVIZ?&lt;/strong&gt;
RVIZ does not support X11 windows, and hence ssh -X will not work&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. I have a mac/windows. How do I use RVIZ?&lt;/strong&gt;
Download the virtual machine image that already has the MuSHR stack and follow instructions
&lt;a href=&quot;https://mushr.io/tutorials/quickstart/&quot;&gt;here&lt;/a&gt; (highly recommended)&lt;/p&gt;
&lt;h3 id=&quot;Set-the-ROS-IP's-Variables&quot;&gt;Set the ROS IP's Variables&lt;a class=&quot;anchor-link&quot; href=&quot;#Set-the-ROS-IP's-Variables&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The setup is best shown visually below&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/rviz_setup.png&quot; alt=&quot;&quot; title=&quot;RVIZ Setup&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1) Open &lt;strong&gt;.bashrc&lt;/strong&gt; and set the variables. This will make sure we &lt;strong&gt;dont have to do this everytime&lt;/strong&gt; you open a command shell. (trust me, you have to open a ton of times for testing)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo nano ~/.bashrc
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Go to the last line of the script and add the following lines. Depending on whether you are setting the variables in the car or your laptop, set the &lt;strong&gt;IP ADDRESS&lt;/strong&gt; accordingly.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ROS_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &amp;lt;&amp;lt;LAPTOP_IP_ADDRESS&amp;gt;&amp;gt;
&lt;span class=&quot;nb&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ROS_MASTER_URI&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;http://&amp;lt;&amp;lt;CAR_IP_ADDRESS&amp;gt;&amp;gt;:11311
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For those wondering how to get the IP ADDRESS&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# To get the ip address&lt;/span&gt;
ifconfig
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;LAPTOP IP Address will be dynamic by default and might be pain to enter each time you login. You can use the following script to extract &quot;IP Address&quot; from the configuration.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/software-config/laptop-ip-address.png&quot; alt=&quot;&quot; title=&quot;laptop ip address&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;enp0s17 = wireless interface that shows the IP address&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;laptop-ip-address&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ifconfig enp0s17 | grep &quot;inet&quot; | awk 'NR==1{print $2}'&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;div class=&quot;flash flash-warn&quot;&gt;
    &lt;svg class=&quot;octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap&quot; viewBox=&quot;0 0 10 16&quot; version=&quot;1.1&quot; width=&quot;10&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M10 7H6l3-7-9 9h4l-3 7 9-9z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Important: &lt;/strong&gt;&lt;strong&gt;NETWORK SETTING on the ORACLE VIRTUAL BOX&lt;/strong&gt;
&lt;/div&gt;
Make sure the NETWORK SETTING on the ORACLE VIRTUAL BOX used to load MUSHR SIM (linux image) has &quot;Bridge Adapter&quot; (NAT is default. NAT will NOT work. It will translate the IP from the CAR to SIM and hence wont read any messages)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/network_setting.png&quot; alt=&quot;&quot; title=&quot;Correct Network Setup&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Maps&quot;&gt;Maps&lt;a class=&quot;anchor-link&quot; href=&quot;#Maps&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;For any car to drive, we need maps so that car can understanding the boundaries and navigate accordingly.&lt;/p&gt;
&lt;h3 id=&quot;Create-a-map-of-your-surrounding&quot;&gt;Create a map of your surrounding&lt;a class=&quot;anchor-link&quot; href=&quot;#Create-a-map-of-your-surrounding&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;h4 id=&quot;Use-GMAPPING-Library&quot;&gt;Use GMAPPING Library&lt;a class=&quot;anchor-link&quot; href=&quot;#Use-GMAPPING-Library&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Start each one of following commands in a separate window as suggested &lt;a href=&quot;https://mushr.io/tutorials/navigation&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# Start teleop  (1st window)&lt;/span&gt;
roslaunch mushr_base teleop.launch

&lt;span class=&quot;c1&quot;&gt;# Start gmapping scan (2nd window). MUSHR with a LIDAR publishes on the &amp;quot;base_scan&amp;quot; topic&lt;/span&gt;

rosrun gmapping slam_gmapping scan:&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;scan
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Drive around the house or park or whereever.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tips for producing a good map&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Drive slowly. &lt;/li&gt;
&lt;li&gt;Drive around the same place couple times&lt;/li&gt;
&lt;li&gt;Finish a loop&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can save the built map using the following command. This command will listen to the map topic and save into the image. The map server package does this operation&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rosrun map_server map_saver -f real-floor0
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The map generated will be clumsy at times.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/my_map_untouched.png&quot; alt=&quot;&quot; title=&quot;Map Created By GMAPPING&quot; /&gt;&lt;/p&gt;
&lt;p&gt;But, we can correct it using any photo editing software. After using &lt;a href=&quot;https://www.gimp.org/&quot;&gt;GIMP&lt;/a&gt; it was modified to&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/my_map_touched.png&quot; alt=&quot;&quot; title=&quot;Map After Editing&quot; /&gt;
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;You might to download the file to your local desktop, Open in GIMP/Photoshop to edit the software.
&lt;/div&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#download to local desktop&lt;/span&gt;
scp robot@&amp;lt;&amp;lt;CAR IP&amp;gt;&amp;gt;:~/real-floor0.pgm ~/Desktop/
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#note that this uploads to home folder. Move it to appropriate folder later&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#upload from local desktop to car&lt;/span&gt;
scp  ~/Desktop/real-floor0.pgm robot@&amp;lt;&amp;lt;CAR IP&amp;gt;&amp;gt;:~
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;CROP-Map&quot;&gt;CROP Map&lt;a class=&quot;anchor-link&quot; href=&quot;#CROP-Map&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;By default the map contains an abundance of blank space around the area of detected surfaces&lt;/strong&gt; By default the file will be 16MB, which will slow down the HALTON SAMPLER when you load the maps and run your car. So we need to crop unnecessary part of the image. But care has to be taken not to &lt;em&gt;blindly crop&lt;/em&gt; and lose the origin. For this purpose there is an undocumented utility &lt;a href=&quot;&amp;#39;https://github.com/abhisheksreesaila/blog/blob/master/assets/softwares/crop_map&amp;#39;&quot;&gt;CROP_MAP&lt;/a&gt; to crop the map, removing the blank spaces around the map.In my case, it reduced by 20x.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/map_size_reduce.png&quot; alt=&quot;&quot; title=&quot;Map Dimensions Reduce&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;Edit-CONFIG-files-to-use-the-map&quot;&gt;Edit CONFIG files to use the map&lt;a class=&quot;anchor-link&quot; href=&quot;#Edit-CONFIG-files-to-use-the-map&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Navigate to MUSHR RHC maps directory and place your maps. Note that you need both the PGM and YAML file. 
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;Make sure the YAML file is referring the correct PGM file
&lt;/div&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;roscd mushr_rhc_ros
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; maps

&lt;span class=&quot;c1&quot;&gt;#copy pgm files to the current directory (mushr_base/maps)&lt;/span&gt;
cp &lt;span class=&quot;s2&quot;&gt;&amp;quot;pgm files from whichever directory you have them&amp;quot;&lt;/span&gt; .
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, change the launch files&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#go 1 level higher. Current directory assumed (mushr_base/maps)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ..

&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; launch

&lt;span class=&quot;c1&quot;&gt;#edit launch files. see screenshot&lt;/span&gt;
nano map_server.launch
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/map_server_launch_change.png&quot; alt=&quot;&quot; title=&quot;Map Server Launch File&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;Battery&quot;&gt;Battery&lt;a class=&quot;anchor-link&quot; href=&quot;#Battery&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Battery is one of the most important elements in a self driving car. If the JETSON NANO is not powered long enough, you cannot TEST, DEBUG the car. I tried the NIiMH batteries suggested by the MUSHR team, but due to lmited battery knowledge ended up draining them and hence making it unusable!! So after thorough research, I ended buying LIPO BATTERY pack &lt;a href=&quot;https://www.amazon.com/Zeee-Batteries-Dean-Style-Connector-Vehicles/dp/B076Z778MJ/ref=sr_1_2?dchild=1&amp;amp;keywords=zee+lipos&amp;amp;qid=1599709339&amp;amp;sr=8-2&quot;&gt;here&lt;/a&gt; and battery charger &lt;a href=&quot;https://www.amazon.com/Tenergy-Balance-Charger-Discharger-Connectors/dp/B00466PKE0/ref=sr_1_4?crid=9WRKZ0HRFW1L&amp;amp;dchild=1&amp;amp;keywords=tenergy+battery+charger&amp;amp;qid=1599709438&amp;amp;sprefix=tenergy+batte%2Caps%2C172&amp;amp;sr=8-4&quot;&gt;here&lt;/a&gt;
&lt;div class=&quot;flash flash-error&quot;&gt;
    &lt;svg class=&quot;octicon octicon-alert octicon octicon-alert octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Warning: &lt;/strong&gt;DO NOT IGNORE THIS SECTION. Having a good battery and taking good care of will save you ton of time downstream when you are stuck in code debugging or testing on track. 
&lt;/div&gt;&lt;/p&gt;
&lt;h3 id=&quot;FAQs&quot;&gt;FAQs&lt;a class=&quot;anchor-link&quot; href=&quot;#FAQs&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Why LIPOS Battery (instead of NiMH)?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The advantages of lithium batteries compared to NiMH batteries are undeniable. The weight/power ratio in LiPo batteries is significantly better. LiPo batteries are noticeably lighter and they can store the same amount or more energy relative to their capacity than NiMH batteries. Also,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It costs the same as NiMH&lt;/li&gt;
&lt;li&gt;Using a smart battery charger, control the charge and use it for years!!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Ok, I agree LIPOS are good. What the hell is BALANCE CHARGE vs FAST CHARGE vs SLOW CHARGE vs STORAGE CHARGE? Which one do I use?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;BALANCE CHARGE&lt;/strong&gt;  Charges both the cells inside the battery equally. Use this setting 99.99% of the time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;STORAGE CHARGE&lt;/strong&gt;  Charges the cells in such a way so that you can store them for months (and hence the name). LIPOS if they are allowed to drain, will drain completely and not work this requiring them to jump start.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;FAST and SLOW CHARGE&lt;/strong&gt;  Charges fast and slow as name suggest. Used in certain special cases.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Ok, basic question, How do I connect and charge?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/battery_connection_method.png&quot; alt=&quot;&quot; title=&quot;Battery - Charger Circuit&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://abhisheksreesaila.github.io/blog/images/mushr-build-pics/battery_ui_values.png&quot; alt=&quot;&quot; title=&quot;Battery UI Values&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do I ever going to need buy NiMH Batteries in the HARDWARE list section ?&lt;/strong&gt; No&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;References&quot;&gt;References&lt;a class=&quot;anchor-link&quot; href=&quot;#References&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;http://www.youbot-store.com/wiki/index.php/Visualizing_performance_of_robot_connected_via_SSH_in_Rviz_on_master_device&quot;&gt;Connect to RVIZ from the linux image&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/Final_Steps.png" /><media:content medium="image" url="https://abhisheksreesaila.github.io/blog/images/post-thumbnails/Final_Steps.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>