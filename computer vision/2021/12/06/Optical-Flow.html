<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Optical Flow | ABLearn</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Optical Flow" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Understand the concept of optical flow" />
<meta property="og:description" content="Understand the concept of optical flow" />
<link rel="canonical" href="https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html" />
<meta property="og:url" content="https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html" />
<meta property="og:site_name" content="ABLearn" />
<meta property="og:image" content="https://ablearn.io/images/post-thumbnails/of.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-06T00:00:00-06:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html"},"description":"Understand the concept of optical flow","@type":"BlogPosting","url":"https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html","headline":"Optical Flow","dateModified":"2021-12-06T00:00:00-06:00","datePublished":"2021-12-06T00:00:00-06:00","image":"https://ablearn.io/images/post-thumbnails/of.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ablearn.io/feed.xml" title="ABLearn" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Optical Flow | ABLearn</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Optical Flow" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Understand the concept of optical flow" />
<meta property="og:description" content="Understand the concept of optical flow" />
<link rel="canonical" href="https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html" />
<meta property="og:url" content="https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html" />
<meta property="og:site_name" content="ABLearn" />
<meta property="og:image" content="https://ablearn.io/images/post-thumbnails/of.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-06T00:00:00-06:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html"},"description":"Understand the concept of optical flow","@type":"BlogPosting","url":"https://ablearn.io/computer%20vision/2021/12/06/Optical-Flow.html","headline":"Optical Flow","dateModified":"2021-12-06T00:00:00-06:00","datePublished":"2021-12-06T00:00:00-06:00","image":"https://ablearn.io/images/post-thumbnails/of.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://ablearn.io/feed.xml" title="ABLearn" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">ABLearn</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Categories</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Optical Flow</h1><p class="page-description">Understand the concept of optical flow</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-06T00:00:00-06:00" itemprop="datePublished">
        Dec 6, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Computer Vision">Computer Vision</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Optical-Flow-vs-Motion-Field">Optical Flow vs Motion Field </a></li>
<li class="toc-entry toc-h1"><a href="#Optical-Flow-Assumptions">Optical Flow Assumptions </a></li>
<li class="toc-entry toc-h1"><a href="#Optical-Flow-Estimation">Optical Flow Estimation </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Sparse-Optical-Flow">Sparse Optical Flow </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Load-Images">Load Images </a></li>
<li class="toc-entry toc-h3"><a href="#Feature-Extraction">Feature Extraction </a></li>
<li class="toc-entry toc-h3"><a href="#Run-Optical-Flow">Run Optical Flow </a></li>
<li class="toc-entry toc-h3"><a href="#Visualize">Visualize </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Deep-Optical-Flow">Deep Optical Flow </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Calculate-Optical-Flow">Calculate Optical Flow </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#References">References </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-12-06-Optical Flow.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the previous blog post <a href="https://ablearn.io/computer%20vision/2021/12/05/Image-Features-Understanding.html">here</a> we understand basics of "features" in an image. One of the most popular usecases for such tracking of features between 2 images would be detection motion of objects within the image.</p>
<h1 id="Optical-Flow-vs-Motion-Field">
<a class="anchor" href="#Optical-Flow-vs-Motion-Field" aria-hidden="true"><span class="octicon octicon-link"></span></a>Optical Flow vs Motion Field<a class="anchor-link" href="#Optical-Flow-vs-Motion-Field"> </a>
</h1>
<p>Let's try to understand the terms first.</p>
<p>We take a object in the world (represented in the world coordinates) and project them onto a image plane. As the object moves in the world, we want to track it in the image plane.  This tracking is called <em>MOTION FIELD</em></p>
<p>It is not possible to directly measure motion field since all we have in the image are brightness patterns.</p>
<p>Using the variation in brightness patterns between consecutives images can help you track the object(s). This is called <em>OPTICAL FLOW</em>.</p>
<p>OPTICAL FLOW indicates MOTION of objects in most of the cases. But there could be images with "illusions" that changes brightness patterns but does not correspond to "object movement" in them". For eg. see below.</p>
<hr>
<p>The object is moving but there is no change in brightness pattern. So very hard to detect motion</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/op1.png" alt="" title="Motion Field without Optical Flow"></p>
<p>Here the light source is moving and hence the brightness pattern is changing, but there is no motion.</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/general/mf1.png" alt="" title="Optical Flow without Motion Field"></p>
<h1 id="Optical-Flow-Assumptions">
<a class="anchor" href="#Optical-Flow-Assumptions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Optical Flow Assumptions<a class="anchor-link" href="#Optical-Flow-Assumptions"> </a>
</h1>
<p>Before we attempt to compute the optical flow. Lets assume 2 things</p>
<ol>
<li>Brightness of a image point remains constant over time. Since we will be dealing with images taken in quick succession (in the order of milliseconds) this is a safe assumption. </li>
</ol>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/opticalfloweq.png" alt="" title="Object moving in an image"></p>
<p>Mathemtically written as</p>
<blockquote>
<p>$I(x+ \delta x, y+ \delta y, t+ \delta t) = I(x, y, t)$</p>
</blockquote>
<ol>
<li>Displacement ($ \delta x, \delta y $) is very small</li>
</ol>
<h1 id="Optical-Flow-Estimation">
<a class="anchor" href="#Optical-Flow-Estimation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Optical Flow Estimation<a class="anchor-link" href="#Optical-Flow-Estimation"> </a>
</h1>
<p>We will look at the "classic" methods of optical flow estimation. OPENCV provides a lot of inbuilt methods to compute them</p>
<h2 id="Sparse-Optical-Flow">
<a class="anchor" href="#Sparse-Optical-Flow" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sparse Optical Flow<a class="anchor-link" href="#Sparse-Optical-Flow"> </a>
</h2>
<p>We compute optical flow by extracting important features only. We will use the "feature extraction" techniques from the <a href="https://ablearn.io/computer%20vision/2021/12/05/Image-Features-Understanding.html">earlier blog post</a> and determine the optical flow. Sparse Optical Flow is fast but not very accurate.
The code is available here.</p>
<p>For this exercise we use the dataset from <a href="http://www.cvlibs.net/datasets/kitti/">KITTI Vision Car Dataset</a> available here.</p>
<h3 id="Load-Images">
<a class="anchor" href="#Load-Images" aria-hidden="true"><span class="octicon octicon-link"></span></a>Load Images<a class="anchor-link" href="#Load-Images"> </a>
</h3>
<div class="highlight"><pre><span></span><span class="c1">#Load two consecutive images</span>
<span class="n">img1</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">"images/000199_10.png"</span><span class="p">)</span>
<span class="n">img2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">"images/000199_11.png"</span><span class="p">)</span>

<span class="c1">#Convert both images to grayscale</span>
<span class="c1">## We need the gray scale images for the functions below</span>
<span class="n">gray1</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">im1</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">gray2</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">im2</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
</pre></div>
<h3 id="Feature-Extraction">
<a class="anchor" href="#Feature-Extraction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Feature Extraction<a class="anchor-link" href="#Feature-Extraction"> </a>
</h3>
<p>We will use the Shi-Tomasi corner detector from OPENCV. To understand how to define the parameters, you can use <a href="https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#ga1d6bb77486c8f92d79c8793ad995d541">this link</a></p>
<div class="highlight"><pre><span></span><span class="n">feature_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">maxCorners</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="n">qualityLevel</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">minDistance</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">blocksize</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">prev</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">goodFeaturesToTrack</span><span class="p">(</span><span class="n">gray1</span><span class="p">,</span><span class="n">feature_params</span><span class="p">[</span><span class="s1">'maxCorners'</span><span class="p">],</span> <span class="n">feature_params</span><span class="p">[</span><span class="s2">"qualityLevel"</span><span class="p">],</span> <span class="n">feature_params</span><span class="p">[</span><span class="s2">"minDistance"</span><span class="p">],</span> <span class="n">feature_params</span><span class="p">[</span><span class="s2">"blocksize"</span><span class="p">])</span>
</pre></div>
<p>By obtaining the features and drawing them, we obtain the following similar to below.</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/sparse-optical-flow-fe.png" alt="" title="Corners detected (features) extracted from the image"></p>
<h3 id="Run-Optical-Flow">
<a class="anchor" href="#Run-Optical-Flow" aria-hidden="true"><span class="octicon octicon-link"></span></a>Run Optical Flow<a class="anchor-link" href="#Run-Optical-Flow"> </a>
</h3>
<p>Launch the Lucas Kanade Optical Flow algorithm (<em>cv2.calcOpticalFlowPyrLK</em>) with the features and both grayscale images.</p>
<div class="highlight"><pre><span></span><span class="n">lk_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">winSize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span> <span class="p">,</span> <span class="n">maxLevel</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">,</span> <span class="n">criteria</span> <span class="o">=</span> <span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">TERM_CRITERIA_EPS</span> <span class="o">|</span> <span class="n">cv2</span><span class="o">.</span><span class="n">TERM_CRITERIA_COUNT</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">))</span>

<span class="c1"># img1 and img2 = images</span>
<span class="c1"># prev = features of the first image</span>
<span class="nb">next</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">error</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calcOpticalFlowPyrLK</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span> <span class="n">img2</span><span class="p">,</span> <span class="n">prev</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">winSize</span><span class="o">=</span><span class="n">lk_params</span><span class="p">[</span><span class="s2">"winSize"</span><span class="p">],</span> <span class="n">maxLevel</span><span class="o">=</span><span class="n">lk_params</span><span class="p">[</span><span class="s2">"maxLevel"</span><span class="p">],</span><span class="n">criteria</span><span class="o">=</span><span class="n">lk_params</span><span class="p">[</span><span class="s2">"criteria"</span><span class="p">])</span>


<span class="c1">#Store the Matches (status=1 means a match)</span>
<span class="n">good_old</span> <span class="o">=</span> <span class="n">prev</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">good_new</span> <span class="o">=</span> <span class="nb">next</span><span class="p">[</span><span class="n">status</span> <span class="o">==</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<h3 id="Visualize">
<a class="anchor" href="#Visualize" aria-hidden="true"><span class="octicon octicon-link"></span></a>Visualize<a class="anchor-link" href="#Visualize"> </a>
</h3>
<p>Go through each matched feature, and draw it on the second image</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/opticalflowop1.png" alt="" title="Optical Flow Output"></p>
<p>Here is a video for a more intuitive show of the optical flow

</p>
<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/mNGbiAWzRSw" frameborder="0" allowfullscreen=""></iframe>
</center>

<h2 id="Deep-Optical-Flow">
<a class="anchor" href="#Deep-Optical-Flow" aria-hidden="true"><span class="octicon octicon-link"></span></a>Deep Optical Flow<a class="anchor-link" href="#Deep-Optical-Flow"> </a>
</h2>
<p>In Deep Optical Flow we compute optical flow for every pixel. Just to clarify, we dont use deep learning (yet!)</p>
<p>The full code is available here</p>
<ol>
<li>Load the images using openv functions as before</li>
</ol>
<h3 id="Calculate-Optical-Flow">
<a class="anchor" href="#Calculate-Optical-Flow" aria-hidden="true"><span class="octicon octicon-link"></span></a>Calculate Optical Flow<a class="anchor-link" href="#Calculate-Optical-Flow"> </a>
</h3>
<p>Wait! no feature extraction? Yes thats correct. Since we are runnning optical flow on every pixel, we can directly use the corresponding opencv function. If you'd like to understand how to tweak the parameters, you can visit this <a href="https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback">link</a></p>
<div class="highlight"><pre><span></span><span class="n">flow</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">calcOpticalFlowFarneback</span><span class="p">(</span><span class="n">gray1</span><span class="p">,</span> <span class="n">gray2</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Shapes Gray &amp; Flow"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gray1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">flow</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">" "</span><span class="p">)</span>

<span class="sd">"""</span>
<span class="sd">Shapes Gray &amp; Flow</span>
<span class="sd">(376, 1241)</span>
<span class="sd">(376, 1241, 2)</span>
<span class="sd">"""</span>
</pre></div>
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>Here flow is a 2d matrix which has the same shape as input but contains the "$ \delta x $" (represented by U) and "$ \delta y$" (represented by V) for each point (X,Y).  
</div>
<img src="https://abhisheksreesaila.github.io/blog/images/stereo/flow-shown.png" alt="" title="Flow Matrix Shown Visually">
<p>Accorinding to OPENCV, we get U and V in cartesian coordinates. To show this visually it will be good if we can find "magnitude" and "direction".  then we will intuitively know how much it moved and in what angle. Catesian system does not provide that.  Luckily for us, "polar system coordinates" gives us what we want.</p>
<div class="highlight"><pre><span></span><span class="n">magnitude</span><span class="p">,</span> <span class="n">angle</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cartToPolar</span><span class="p">(</span><span class="n">flow</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">flow</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
<p>
</p>
<center>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/QkuOY7AObh8" frameborder="0" allowfullscreen=""></iframe>
</center>


</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References<a class="anchor-link" href="#References"> </a>
</h1>
<p><a href="https://www.youtube.com/watch?v=lnXFcmLB7sM&amp;t=92s">Optical Flow Definition</a></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="abhisheksreesaila/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/computer%20vision/2021/12/06/Optical-Flow.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Always Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/abhisheksreesaila" target="_blank" title="abhisheksreesaila"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/asreesaila" target="_blank" title="asreesaila"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
