<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Stereo Vision | ABLearn</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Stereo Vision" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Two eyes are always better than one!" />
<meta property="og:description" content="Two eyes are always better than one!" />
<link rel="canonical" href="https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html" />
<meta property="og:url" content="https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html" />
<meta property="og:site_name" content="ABLearn" />
<meta property="og:image" content="https://ablearn.io/images/post-thumbnails/sv2.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-07T00:00:00-06:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html"},"description":"Two eyes are always better than one!","@type":"BlogPosting","url":"https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html","headline":"Stereo Vision","dateModified":"2021-12-07T00:00:00-06:00","datePublished":"2021-12-07T00:00:00-06:00","image":"https://ablearn.io/images/post-thumbnails/sv2.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ablearn.io/feed.xml" title="ABLearn" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Stereo Vision | ABLearn</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Stereo Vision" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Two eyes are always better than one!" />
<meta property="og:description" content="Two eyes are always better than one!" />
<link rel="canonical" href="https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html" />
<meta property="og:url" content="https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html" />
<meta property="og:site_name" content="ABLearn" />
<meta property="og:image" content="https://ablearn.io/images/post-thumbnails/sv2.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-07T00:00:00-06:00" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html"},"description":"Two eyes are always better than one!","@type":"BlogPosting","url":"https://ablearn.io/computer%20vision/2021/12/07/StereoVision.html","headline":"Stereo Vision","dateModified":"2021-12-07T00:00:00-06:00","datePublished":"2021-12-07T00:00:00-06:00","image":"https://ablearn.io/images/post-thumbnails/sv2.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://ablearn.io/feed.xml" title="ABLearn" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">ABLearn</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Categories</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Stereo Vision</h1><p class="page-description">Two eyes are always better than one!</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-07T00:00:00-06:00" itemprop="datePublished">
        Dec 7, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Computer Vision">Computer Vision</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#The-loss-of-depth">The loss of depth </a></li>
<li class="toc-entry toc-h1"><a href="#How-to-recover?">How to recover? </a></li>
<li class="toc-entry toc-h1"><a href="#Finding-Depth">Finding Depth </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Problems-with-stereo-matching">Problems with stereo matching </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Calibration-of-the-Stereo">Calibration of the Stereo </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Epipolar-Geometry">Epipolar Geometry </a></li>
<li class="toc-entry toc-h2"><a href="#Now-why-do-we-care-about-epipolar-geometry?">Now why do we care about epipolar geometry? </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Epipolar-Constraint">Epipolar Constraint </a></li>
<li class="toc-entry toc-h3"><a href="#How-does-this-work-in-practice?">How does this work in practice? </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Finding-correspondence">Finding correspondence </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Computing-Depth">Computing Depth </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#References">References </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-12-07-StereoVision.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-loss-of-depth">
<a class="anchor" href="#The-loss-of-depth" aria-hidden="true"><span class="octicon octicon-link"></span></a>The loss of depth<a class="anchor-link" href="#The-loss-of-depth"> </a>
</h1>
<p>Given a point in the image plane (U, V), can we find a corresponding point in the world system? The answer is NO.  When we move capture a image we know that 3d world coordinate gets transformed to camera cooridinate and then a 2D image plane. Refer to this blog post for indepth details. Since we loose information, more specifically "Z" depth information, it is impossible to get it back.  In other words, given an image point you cannot reverse engineer WORLD coordinate since you have lost a crucial "Z" coordinate in the translation process. however, you havent lost "X", "Y".  There is hope to get it back, but we need additional help.</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/monocular2.png" alt="" title="Loss of Depth"></p>
<p>Since we know "X", "Y", we know it exists somewhere along the line shown as dotted green lines. Why? This was the same line which was used in the projection of object onto the image plane to derive all the math. So, it can also assist in the reverse direction as well.</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/projection2.png" alt="" title="Projection of the object on image plane"></p>
<h1 id="How-to-recover?">
<a class="anchor" href="#How-to-recover?" aria-hidden="true"><span class="octicon octicon-link"></span></a>How to recover?<a class="anchor-link" href="#How-to-recover?"> </a>
</h1>
<p>The trick is to understand how nature does this. We all have 2 eyes, and we perceive depth (3d) in all objects. Don't we? The "second eye" provides its view of the world  in addition to the first, and both together work together perceive depth.</p>
<p>Lets apply the same concept here. lets bring in another camera, place it horizontally along the same axis at a distance, find the exact same spot (U, V) on it, guess the point on the "dotted green line".  The intersection of these 2 dotted green lines gives you the depth Z.  See below for the visual</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/stereo.png" alt="" title="Stereo Vision"></p>
<ul>
<li>$ u_r v_r $ and  $ u_l v_l $ are the exact same point of the image as seen in the right and left camera respectively</li>
<li>the distance between the cameras is called baseline denoted by b</li>
<li>the camera plane is placed at the pinhole with origin (0,0,0) on the left and (b,0,0) on the right</li>
<li>P (x, y, z) is the scene point that we are trying to compute using the 2 cameras.</li>
</ul>
<p>This concept of using 2 cameras to perceive depth in the real world is called Simple Stereo Vision.  In this blog post lets understand the mechanics of such a system.</p>
<h1 id="Finding-Depth">
<a class="anchor" href="#Finding-Depth" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding Depth<a class="anchor-link" href="#Finding-Depth"> </a>
</h1>
<p>Lets start with the basics. For a pinhole based camera system we know the following equations</p>
<p>$ u_l = f_x * x/z + O_x $  ;   $ v_l = f_y * y/z  + O_y $</p>
<p>For the right camera, its the same but the camera axis is shifted by "b"</p>
<p>$ u_r = f_x * x/z + O_x $  ;   $ v_r = f_y * y/z  + O_y $</p>
<p>Using the 4 equations, solving for x, y, z  we get</p>
<p>$ x = \frac {b (u_l - O_x)}{ u_l - u_r } $
$ y = \frac {b f_x (v_l - O_y)}{f_y (u_l - u_r)} $
$ z = \frac {b f_x}{ u_l - u_r } $</p>
<p>Where $ u_l - u_r $ is called disparity and its inversely propotional to "z" 
</p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 10 16" version="1.1" width="10" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10 7H6l3-7-9 9h4l-3 7 9-9z"></path></svg>
    <strong>Important: </strong>If we know the internal parameters fx, fy, ox, oy and compute disparity, we compute Z and hence the depth. 
</div>
<p>If the object is closer to the camera, you will see a large disparity. for example, U value in the left camera will be 100, whereas the right camera it will be 75.  This is exact same pixel in the image but having 2 different values. The opposite is also true i.e the object is far, there will be very less difference between the U values (Say 100 and 95).  At infinite distance, U values will exactly be the same.</p>
<p>Disparity is propotional to baseline meaning if the distance between camera increase, disparity will increase.</p>
<p>I keep mentioning only "U" because there is no $v_l - v_r $ in the equation. which means only the horizontal component between the 2 cameras vary not the "vertical component".  This proporty shows that  $ u_r, v_r $ and $ u_l $ and $ v_l $ lie along the same line (show by the yellow line). when we are computing DISPARITY to solve for X, Y, Z  in the real world, we can pick a point in the left camera $ (u_l, v_l) $ and  ONLY search along the same line in the right camera (and not wander aimlessly and search the whole image) to get the $ u_r, v_r $ .i.e  its a "1D" search problem. See image below for an example. This is often called the <strong>"correspondence problem"</strong></p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/texture.png" alt="" title="Finding Correspondence"></p>
<p>The white patch in the picture is called the "scan line".</p>
<h2 id="Problems-with-stereo-matching">
<a class="anchor" href="#Problems-with-stereo-matching" aria-hidden="true"><span class="octicon octicon-link"></span></a>Problems with stereo matching<a class="anchor-link" href="#Problems-with-stereo-matching"> </a>
</h2>
<p>Did we solve of finding depth just by solving 2 cameras? yes for the most part, but if the images have the repetitive texture, its impossible to compute disparity and therefore can't compute depth.  see image below.</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/no-texture.png" alt="" title="Stereo Vision CANNOT be computed"></p>
<h1 id="Calibration-of-the-Stereo">
<a class="anchor" href="#Calibration-of-the-Stereo" aria-hidden="true"><span class="octicon octicon-link"></span></a>Calibration of the Stereo<a class="anchor-link" href="#Calibration-of-the-Stereo"> </a>
</h1>
<p>In the section above we assumed the stereo is calibrated that means we know the how they are aligned with respect to each other.</p>
<p>Suppose we take a photo of effiel tower on a iphone. Then another person take a same photo with a slight different angle from samsung android phone. Is it possible to compute Z depth information and hence reocover the 3d structure of the image?  The answer turns out to be yes.</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/Uncalibrated-stereo.png" alt="" title="Uncalibrated Stereo"></p>
<p>Every digital camera embeds certain metadata within the image such as the focal length etc. which can be read as internal parameters. All we need to compute are the external parameters.</p>
<p>In practice if there are 2 camera taking a shot at the same picture at 2 different angles, if we know the internal parameters of each camera, then we can calculate the alignment ourselves and hence compute the depth.  that is what we will explore in this section</p>
<p>Consider the above picture.  It is identical to the one in the earlier section except that left and right cameras have their own coordinate system $(x_l,y_l, z_l)$ and $ (x_r, y_r, z_r)$ respectively.</p>
<p>Our goal is to compute the "translation" and "rotation" of one camera w.r.t the other.</p>
<h2 id="Epipolar-Geometry">
<a class="anchor" href="#Epipolar-Geometry" aria-hidden="true"><span class="octicon octicon-link"></span></a>Epipolar Geometry<a class="anchor-link" href="#Epipolar-Geometry"> </a>
</h2>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/epipolar_geo.png" alt="" title="Epipolar Plane"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>The highlighted triangle is "Epipolar Plane". Its the plane formed by the scene point (P) and camera origins $ o_l $  and $ o_r $ is called epipolar plane</p>
</li>
<li>
<p>$e_l$ and $e_r$ are the projection of camera's origin on the left and right image planes respectively.  They are also called epipoles</p>
</li>
<li>
<p>Every scene point will have it own epipolar plane.</p>
</li>
</ul>
<h2 id="Now-why-do-we-care-about-epipolar-geometry?">
<a class="anchor" href="#Now-why-do-we-care-about-epipolar-geometry?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Now why do we care about epipolar geometry?<a class="anchor-link" href="#Now-why-do-we-care-about-epipolar-geometry?"> </a>
</h2>
<blockquote>
<p>Our goal is to find a equation such that we can calculate t, R (translation, Rotation)</p>
</blockquote>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/epipolar_cons.png" alt="" title="Epipolar Constraint"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Epipolar-Constraint">
<a class="anchor" href="#Epipolar-Constraint" aria-hidden="true"><span class="octicon octicon-link"></span></a>Epipolar Constraint<a class="anchor-link" href="#Epipolar-Constraint"> </a>
</h3>
<p>Consider a vector perpendicular to $X_l$ (highlighted in pink). Lets call it N</p>
<p>From linear algebra,</p>
<ul>
<li>N = Cross Product between t and $X_l$</li>
<li>N = t X $X_l$....(1)
Also, <ul>
<li>$X_l$ * N = 0 (dot product of N and $X_l$ is 0).....(2)</li>
</ul>
</li>
</ul>
<p>Hence from (1) and (2)</p>
<p>(t X $X_l$) * $X_l$ = 0</p>
<blockquote>
<p>This is the epipolar constraint.</p>
</blockquote>
<p>$X_l$ is a vector composed of elements $(x_l, y_l, z_l)$ and $x_l = R x_r + t$ (from the perspective projection)
Where t = position of right camera w.r.t to left; R = orientation of right camera w.r.t to left. At the end you will end up with</p>
<blockquote>
<p>$X_l$ E $X_r$ = 0   ...(1)</p>
</blockquote>
<ul>
<li>
<p>E is a 3x3 matrix called the Essential Matrix</p>
<p>But we notice $X_l$ and $X_r$ stil exists! Our goal is to find these values.  So using perspective projection,</p>
</li>
</ul>
<p>$ u = f_x * x_l/z_l + O_x $  ;   $ v = f_y * y_l/z_l + O_y $  Where $ f_x and f_x $ are focal lengths measured in pixels</p>
<p>Substituting for $x_l$ in equation (1) and expressing in matrix form, we get rid of $x_l$  and $y_l$. but $z_l$ remains!  But $z_l$ can never be 0, since it the depth. In common man terms, the world exists infront of the camera, so world coordinate will have some value of "z", hence z &lt;&gt; 0. Using these concepts we arrive at</p>
<blockquote>
<p>$U_l  K^{-1}_l E K^{-1}_r U_r$ = 0</p>
<p>$U_l$ F $U_r$ = 0</p>
</blockquote>
<p>where $U_l$ =  $[u_l, v_l, 1]$</p>
<p>and $U_r$ = $$ \begin{bmatrix} u_r \\  v_r \\  1 \end{bmatrix} $$</p>
<p>Where F is called fundamental matrix. I have intentionally skipped the math but for those mathematically inclined check out explanation <a href="https://www.youtube.com/watch?v=6kpBqfgSPRc">here</a></p>
<h3 id="How-does-this-work-in-practice?">
<a class="anchor" href="#How-does-this-work-in-practice?" aria-hidden="true"><span class="octicon octicon-link"></span></a>How does this work in practice?<a class="anchor-link" href="#How-does-this-work-in-practice?"> </a>
</h3>
<ol>
<li>Suppose we are given the "F" matrix, we can easily get "E" since we "K" is given to us</li>
</ol>
<ol>
<li>Once you get E from step 1, then a technique called "<a href="https://keisan.casio.com/exec/system/15076953160460">singular value decomposition</a>" we can decompose it into "t" and "R"</li>
</ol>
<h2 id="Finding-correspondence">
<a class="anchor" href="#Finding-correspondence" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding correspondence<a class="anchor-link" href="#Finding-correspondence"> </a>
</h2>
<p>In the previous sectionn, we said given a point $u_l, v_l$ finding a matching point $u_r v_r$ is a 1D search problem i.e. we have to search only in 1 direction, horizontally. But wait! where?  Can epipolar geometry help in the telling me the section the image to search?</p>
<p>Fortunately the answer is yes! There is only other component of EPIPOLAR geometry to the rescue! Epipolar line.</p>
<p>Imagine looking at the second camera origin, all the points on the $X_l$ will fall on the image plane as shown in red. also, this red line will intersect with the epipolar plane. This intersection is the epipolar line. In other words, The projection of all the points on the vector $X_l$ will lie on a line called EPIPOLAR line.</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/epipolar-line.png" alt="" title="Epipolar line"></p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/epipolarline2.png%20%5Bsource%5D(https://en.wikipedia.org/wiki/Epipolar_geometry" alt="">)</p>
<p><img src="https://abhisheksreesaila.github.io/blog/images/stereo/epipolar-formation.gif" alt="" title="Epipolar line Formation- Animated"></p>
<p>From the last section, we have</p>
<blockquote>
<p>$U_l$ F $U_r$ = 0</p>
</blockquote>
<p>Expanding..</p>
$$


\begin{bmatrix} u_{l} \\  v_{l} \\  1  \end{bmatrix}

\begin{bmatrix} f_{11} &amp; f_{12} &amp; f_{13} \\  f_{21} &amp; f_{22} &amp; f_{23}  \\  f_{31} &amp; f_{32} &amp; f_{33}  \end{bmatrix}

\begin{bmatrix} u_r \\  v_r \\  1 \end{bmatrix}

=  0

$$<p>Multiplying...</p>
<p>$(f_{11}u_l +f_{12}v_l + f_{31})u_r + (f_{21}u_l +f_{22}v_l + f_{32})v_r + (f_{13}u_l +f_{23}v_l + f_{33})= 0 $</p>
<p>Simplified to...</p>
<p>$Au_r + Bv_r + C = 0$ is a simple linear equation of the line that has all the projection points of $X_l$</p>
<blockquote>
<p>This is the equation for the epipolar line</p>
</blockquote>
<h3 id="Computing-Depth">
<a class="anchor" href="#Computing-Depth" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computing Depth<a class="anchor-link" href="#Computing-Depth"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">
<a class="anchor" href="#References" aria-hidden="true"><span class="octicon octicon-link"></span></a>References<a class="anchor-link" href="#References"> </a>
</h1>
<p><a href="https://www.youtube.com/watch?v=hUVyDabn1Mg">Stereo Vision</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="abhisheksreesaila/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/computer%20vision/2021/12/07/StereoVision.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Always Learning</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/abhisheksreesaila" target="_blank" title="abhisheksreesaila"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/asreesaila" target="_blank" title="asreesaila"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
